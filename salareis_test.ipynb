{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24613ff",
   "metadata": {},
   "source": [
    "# Analyzing UMD Professor Salary and Review\n",
    "### By Sean Huang and Tochukwu Ibe-Ekeocha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-finder",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-chocolate",
   "metadata": {},
   "source": [
    "In this project we want to analyze a two main datasets from the University of Maryland College Park. The first is data about the salaries of all the professors at the University as well as Student created reviews of classes taught by the professors. Our goal it to use a number of tools and methodologies from the data science pipeline to use the datasets to make meaningful insights about the relationship between professor salary and student course review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87249c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import requests\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os.path\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a8a36",
   "metadata": {},
   "source": [
    "## Data  Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-settlement",
   "metadata": {},
   "source": [
    "To start, we first need some data on both the salaries of each professors in the university as well as their popularity. Since popularity is somewhat abstract and subjective, we decided to use the review that they recieved from their past students. For the salary data, we found a website called the Diamondback Salary Guide(https://salaryguide.dbknews.com/), a platform that allows the user to look up any university staff and get their salary, department, and position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c421d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sql.connect(\":memory:\")\n",
    "sqlite_file = 'salaries_data.sql'\n",
    "sql_file = open(sqlite_file)\n",
    "sql_as_string = sql_file. read()\n",
    "db. executescript(sql_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52922b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_query= \"\"\"\n",
    "SELECT \n",
    " firstname, lastname, department, salary, position\n",
    "FROM Salaries\n",
    "\"\"\"\n",
    "\n",
    "salaries = pd.read_sql(salary_query, db)\n",
    "\n",
    "salaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-withdrawal",
   "metadata": {},
   "source": [
    "For the review data, we used PlanetTerp, the official review site for UMD professors. Since the process of pulling every single professor from PlanetTerp takes a long time, we decided to check if there is a local database we can use before calling the API, and just using the local data if one is found. If one is not found, we fetch the professors 1000 at a time, using the API. After we fetch them, we save it locally so we don't have to do wait next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37822e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_profs(): \n",
    "    profs = dict()\n",
    "    matched_profs = dict()\n",
    "\n",
    "    for i in range(0, 10000, 1000):\n",
    "        r = requests.get('https://api.planetterp.com/v1/professors?reviews=true', params={\n",
    "          'limit': '1000',\n",
    "          'offset': i,\n",
    "        }, headers = {'Accept': 'application/json'})\n",
    "\n",
    "        for e in r.json():\n",
    "            profs[e.get(\"slug\")] = e\n",
    "            matched_profs[e.get(\"slug\")] = None\n",
    "    return (profs, matched_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ac5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reviewsData(_data, ids):\n",
    "    if(path.isfile(\"reviews.csv\")):\n",
    "        return pd.read_csv(\"reviews.csv\")\n",
    "        \n",
    "    reviews_data = []\n",
    "    i = 0\n",
    "    for v in _data:\n",
    "\n",
    "        r = requests.get('https://api.planetterp.com/v1/professor', params={\n",
    "          'name': v,  'reviews': 'true'\n",
    "        }, headers = {'Accept': 'application/json'}).json()\n",
    "\n",
    "\n",
    "        slug = r.get(\"slug\")\n",
    "        revs = r.get(\"reviews\")\n",
    "        if(revs == None):\n",
    "            continue\n",
    "\n",
    "        for rev in revs:  \n",
    "\n",
    "            reviews_data.append([ \n",
    "                slug,\n",
    "                rev.get(\"rating\"),  \n",
    "                rev.get(\"expected_grade\"), \n",
    "                rev.get(\"course\"),\n",
    "                rev.get(\"review\"),\n",
    "                ids[i]\n",
    "            ])\n",
    "            \n",
    "        i += 1;\n",
    "    reviews_df = pd.DataFrame(reviews_data, columns=['slug', 'rating', 'expected_grade', 'course', 'review', \"prof_df_id\"])\n",
    "    reviews_df.to_csv(path_or_buf=\"reviews.csv\", index=False)\n",
    "    return  reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-rocket",
   "metadata": {},
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f04e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fetch_matched_salaries():\n",
    "    if(path.isfile(\"matched_salaries.csv\")):\n",
    "        return pd.read_csv(\"matched_salaries.csv\")\n",
    "    \n",
    "    \n",
    "    (profs, matched_profs) = fetch_profs()\n",
    "    \n",
    "    arr = list(set(salaries[\"department\"]))\n",
    "    for dep in arr:   \n",
    "        get_department(dep, profs, matched_profs)\n",
    "        \n",
    "    data = [ list(v)  for v in matched_profs.values() if v != None]\n",
    "    matched_salaries = pd.DataFrame(data, columns=['firstname', 'lastname', 'department', 'salary', \"position\", \"avg_rating\", 'slug', \"planetTerpName\", \"courses\", \"num_courses\"])\n",
    "    matched_salaries.to_csv(path_or_buf=\"matched_salaries.csv\", index=False)\n",
    "    return matched_salaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-hudson",
   "metadata": {},
   "source": [
    "We now have two data sets with information on UMD's profesors. Since they came from two different places and uses different format, we will have to merge them manually. To do this, we wrote a function called find_closest_match(), which find the closest match for a name in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_match(name, matches):\n",
    "    firstname = name.split(\" \")[0]\n",
    "    ret = [ m  for m in matches if m[0].find(firstname) >= 0 ]\n",
    "    if(len(ret) > 0):\n",
    "        return ret[0]\n",
    "    return None\n",
    "def calc_avg_review(revs):\n",
    "    length = len(revs)\n",
    "    if(length == 0):\n",
    "        return np.nan\n",
    "    total = 0\n",
    "    for r in revs:\n",
    "        total += r.get(\"rating\")\n",
    "    return total / length\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-diving",
   "metadata": {},
   "source": [
    "With a simple helper method, we are also able to parse each professor's information into columns in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda78e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_department(dep, profs, matched_profs):\n",
    "    matches = dict()\n",
    "\n",
    "    for prof in profs.values():\n",
    "        \n",
    "        slug = prof.get(\"slug\")\n",
    "        name = prof.get(\"name\")\n",
    "        courses = prof.get(\"courses\")\n",
    "        avg_rating = calc_avg_review(prof.get(\"reviews\"))\n",
    "        \n",
    "        if(matched_profs.get(slug) != None):\n",
    "            continue\n",
    "\n",
    "        lastname = name.split(\" \")[-1]\n",
    "\n",
    "        salary_query= f\"\"\"\n",
    "            SELECT \n",
    "            firstname, \n",
    "            lastname,\n",
    "            department,\n",
    "            salary,\n",
    "            position\n",
    "            FROM Salaries\n",
    "            WHERE lastname like \"{lastname}\"\n",
    "            AND department = \"{dep}\"\n",
    "        \"\"\"\n",
    "        rows = list(db.execute(salary_query))\n",
    "        matches[lastname] = (len(rows), rows, name, slug, courses, avg_rating)\n",
    "        \n",
    "\n",
    "    for match in matches.keys():\n",
    "        (length, v, name, slug, courses, avg_rating) = matches.get(match)\n",
    "        if(length > 0):\n",
    "           \n",
    "            value = find_closest_match(name, v)\n",
    "         \n",
    "            if(value != None):\n",
    "                \n",
    "                matched_profs[slug] = (\n",
    "                    value[0],\n",
    "                    value[1],\n",
    "                    value[2],\n",
    "                    value[3],\n",
    "                    value[4],\n",
    "                    avg_rating,\n",
    "                    slug,\n",
    "                    name,\n",
    "                    \"-\".join(courses),\n",
    "                    len(courses)\n",
    "                )\n",
    "                \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-interface",
   "metadata": {},
   "source": [
    "Since we are only looking into professors, we filter the database to only inclue those with either \"Lecturer\" or \"Professor\" in their position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f16086",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_salaries = fetch_matched_salaries()\n",
    "matched_salaries = matched_salaries[matched_salaries['position'].str.contains(\"Professor\") | matched_salaries['position'].str.contains(\"Lecturer\")]\n",
    "matched_salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = fetch_reviewsData(list(matched_salaries[\"planetTerpName\"]), matched_salaries.index.values)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37740bf8",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-preserve",
   "metadata": {},
   "source": [
    "In this section, we will start to take a look at the dataset and try to find patterns and correlations that could be relevant and used to form our hypotheses later. To start, we take a look at how a professor's review correlates with the professor's salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (20, 11)\n",
    "prof_salary = matched_salaries.dropna(subset = ['avg_rating'])\n",
    "prof_salary = prof_salary[prof_salary['position'].str.contains(\"Professor\") | prof_salary['position'].str.contains(\"Lecturer\")]\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.scatter(prof_salary['salary'], prof_salary['avg_rating'])\n",
    "plt.xlabel('Salary')\n",
    "plt.ylabel('Average Rating')\n",
    "\n",
    "m,b = np.polyfit(prof_salary['salary'], prof_salary['avg_rating'], 1)\n",
    "plt.plot(prof_salary['salary'], m * prof_salary['salary'] + b, color = 'red')\n",
    "plt.title(\"Salary vs Average Rate by Professsors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-ghost",
   "metadata": {},
   "source": [
    "From this graph, we are able to see that there is a negative correlation with a professor's salary and the average review the professor has. This indicates that professors that are paid more are more likely to have a lower average review on PlanetTerp. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-fiber",
   "metadata": {},
   "source": [
    "We also wanted to see if there is a big difference between the average salary of professors in each department. So, we grouped the professor's salary data by department and found the average salary of each department's professors. We also sorted them to see the top salaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_avg = matched_salaries.groupby(\"department\").mean().sort_values(by=[\"salary\"], ascending=False)\n",
    "dept_avg = dept_avg.dropna()\n",
    "dept_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-camel",
   "metadata": {},
   "source": [
    "According to the dataframe, we can see the top department for average salary being the Business School, the school of Behavioral and Social Science, and the Academy of Innovation & Entrepreneurship. The three schools that gets paid the least are the school of Archeology, Office of Undergraduate Studies, and the school of Enviornmental Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "for i in dept_avg.index:\n",
    "    plt.scatter(dept_avg.loc[i]['salary'], dept_avg.loc[i]['avg_rating'])\n",
    "    plt.annotate(i, (dept_avg.loc[i]['salary'], dept_avg.loc[i]['avg_rating']))\n",
    "    \n",
    "plt.title('Salary vs Average Rating by Departments')\n",
    "plt.xlabel('Salary')\n",
    "plt.ylabel('Average Rating')\n",
    "\n",
    "m,b = np.polyfit(dept_avg['salary'], dept_avg['avg_rating'], 1)\n",
    "\n",
    "\n",
    "plt.plot(dept_avg['salary'], m * dept_avg['salary'] + b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-employer",
   "metadata": {},
   "source": [
    "Just like above, we see the same negative correlation between salary and average rating. However, this graph also brings us information about departments that are outliers. For example, the school of Archeology gets a particularly low rating for its average salary and the the school of Academy of Innovation & Entrepreneurship gets high rating for its salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-tours",
   "metadata": {},
   "source": [
    "We also wanted to see if the amount of unique courses a professor has taught also correlates with the amount of salary that professor earned. So, we created another scatterplot to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_salary = matched_salaries.dropna(subset = ['avg_rating'])\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.scatter(prof_salary['num_courses'], prof_salary['salary'])\n",
    "plt.xlabel('Number of Courses Taught')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Number of Courses Taught vs Salary by Professors')\n",
    "\n",
    "m,b = np.polyfit(prof_salary['num_courses'], prof_salary['salary'], 1)\n",
    "plt.plot(prof_salary['num_courses'], m * prof_salary['num_courses'] + b, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-adolescent",
   "metadata": {},
   "source": [
    "The graph does show a positive correlation between the two, indicating that a professor that has taught many different courses are more likely to have a higher salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-penetration",
   "metadata": {},
   "source": [
    "### Finding general correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-demand",
   "metadata": {},
   "source": [
    "To get a better look of what correlation exists in the dataset, we use a correlation matrix to match each columns with all the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = figsize)\n",
    "g = sns.heatmap(matched_salaries.corr(), annot = True, cmap = \"YlGnBu\", fmt = '.1g', linewidths=.5,)\n",
    "\n",
    "g.set_title(\"Correlation Matrix between Columns\")\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-emergency",
   "metadata": {},
   "source": [
    "There doesn't seem to be any significant correlation with any of the numerical data so far. We decided to include the department data to find any correlations for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-chorus",
   "metadata": {},
   "source": [
    "Since the departments are categorical data, we decide to use the get_dummies function from pandas to convert it to numerical data. The new dataframe include a new column for each of the categories in the department column, and indicates which category it belongs to with a 1 in the department a row belongs to and 0s in all other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_features = pd.get_dummies(matched_salaries['department'], drop_first = True, prefix = 'dept')\n",
    "std_features = matched_salaries[['avg_rating', 'salary', 'num_courses']]\n",
    "\n",
    "#combine our data\n",
    "comb_features = pd.concat([std_features, dept_features], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-original",
   "metadata": {},
   "source": [
    "With the new dummies, we take a look at our updated matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = figsize)\n",
    "g = sns.heatmap(comb_features.corr(), annot = True, cmap = \"YlGnBu\", fmt = '.1g', linewidths=.5,)\n",
    "\n",
    "g.set_title(\"Correlation Matrix between Columns\")\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-celtic",
   "metadata": {},
   "source": [
    "Unfortnunaly, there are still no significant correlation between our data. The two strongest correlations are there are dept_BMGT with salary and dept_ARHU with num_courses. This indicatest that a professor in BMGT is more likely to get a higher salary and a professor in ARHU is more likely to teach many different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525dc5b",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-delicious",
   "metadata": {},
   "source": [
    "### MODEL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30bcc1a",
   "metadata": {},
   "source": [
    "We first try to use a linear regression model to predict a professors salary. Knowing the number of unique courses taught, average rating, and department for each of the professors, we can predict what their salary should be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-oxford",
   "metadata": {},
   "source": [
    "In order to add more context to the data, we need a way to represent relationships between columns in our dataframe. We use the new dataframe we got above to create two interaction terms by multiplying the department column by the number of courses as well as the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_features = comb_features.dropna()\n",
    "for i in filter(lambda i : i!= 'AGNR', matched_salaries['department'].unique()):\n",
    "    comb_features['num_course*' + i] = comb_features['dept_' + i]*comb_features['num_courses']\n",
    "    comb_features['rating*' + i] = comb_features['dept_' + i]*comb_features['avg_rating']\n",
    "    \n",
    "comb_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-election",
   "metadata": {},
   "source": [
    "We fit our data on a linear regression model, where X is the independent variables, which includes all the columns in the dataframe except salary, and Y the dependent variable, which is the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate our data\n",
    "X = comb_features.drop('salary', axis = 1)\n",
    "y = comb_features['salary']\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-castle",
   "metadata": {},
   "source": [
    "After trainng the model, we used it to make predictions on every professors that have the independent variables in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, row in matched_salaries.iterrows():\n",
    "    if i in comb_features.index:\n",
    "        predictions.append(round(reg.predict([X.loc[i]])[0],2))\n",
    "        \n",
    "    else :\n",
    "        predictions.append(np.nan)\n",
    "matched_salaries['predicted_salary'] = predictions\n",
    "matched_salaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-questionnaire",
   "metadata": {},
   "source": [
    "To see how accurate our model is, we make a scatter plot of the predicted salary of each professor vs the actual salary of each professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-packing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(matched_salaries['predicted_salary'], matched_salaries['salary'], color=\"red\")\n",
    "\n",
    "plt.xlabel('Predicted Salary')\n",
    "plt.ylabel('Actual Salary')\n",
    "plt.title('Predicted Salary vs Actual Salary')\n",
    "\n",
    "x = prof_salary['avg_rating']\n",
    "y = prof_salary['salary']\n",
    "\n",
    "plt.plot([0,500000],[0,500000])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-stomach",
   "metadata": {},
   "source": [
    "From the graph, we see that our predictions do follow the same trend as the actual salaries of the professor, especually with professors with lower income. However, there are a few notable cases of under-prediction outliers when it comes to professors with a very high income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-panama",
   "metadata": {},
   "source": [
    "### MODEL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d3ddf",
   "metadata": {},
   "source": [
    "Next we want to use salary, average rating, and department for each student's review to get a lot to predict the grades they got for that class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0edbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary(x): \n",
    "    return matched_salaries.loc[x.prof_df_id][\"salary\"]\n",
    "def get_department(x):\n",
    "    return matched_salaries.loc[x.prof_df_id][\"department\"]\n",
    "    \n",
    "def map_grades(g): \n",
    "    if(pd.isnull(g)):\n",
    "        return np.nan\n",
    "    \n",
    "    d = {'A': 90, \"B\": 80, \"C\": 70, \"D\": 60, \"F\": 50}\n",
    "    match = re.search('[a-z|A-Z]', g, re.IGNORECASE)\n",
    "    if(match == None):\n",
    "        return np.nan\n",
    "    val = d.get(match.group(0))\n",
    "    return val if val != None else np.nan\n",
    "\n",
    "# reviews_df['course_num'] = reviews_df.apply(lambda x: convert_to_num_rep(x.course), axis=1)\n",
    "reviews_df['grade_num'] = reviews_df.apply(lambda x: map_grades(x.expected_grade), axis=1)\n",
    "reviews_df['department'] = reviews_df.apply(lambda x: get_department(x), axis=1)\n",
    "reviews_df['salary'] = reviews_df.apply(lambda x: get_salary(x), axis=1)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-silly",
   "metadata": {},
   "source": [
    "Since grades on a review are given in a letter format, we first convert it into numeric data using an approximation of the precentage the student got as a final grade. We also drop all the reviews without a grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138aee3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "non_missing_grades = reviews_df.dropna()\n",
    "non_missing_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-silicon",
   "metadata": {},
   "source": [
    "For this model, we decided to seperate the data into trainng data and testing data. This means we use the training data to create the model and test the model against the testing data. This strategy helps us to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_sample,  test_sample] = train_test_split(non_missing_grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-tours",
   "metadata": {},
   "source": [
    "Using the same process above, we create interactions terms for the categorical data of department and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df):\n",
    "    dept_features = pd.get_dummies(df['department'], drop_first = True, prefix = 'dept')\n",
    "    std_features = df[['rating', 'grade_num', 'salary']]\n",
    "\n",
    "    comb_features = pd.concat([std_features, dept_features], axis = 1)\n",
    "\n",
    "    for i in filter(lambda i : i!= 'AGNR', non_missing_grades['department'].unique()):\n",
    "        if i in comb_features.index:\n",
    "            comb_features['salary*' + i] = comb_features['dept_' + i]*comb_features['salary']\n",
    "            comb_features['rating*' + i] = comb_features['dept_' + i]*comb_features['rating']\n",
    "        else:\n",
    "            comb_features['salary*' + i] = 0\n",
    "            comb_features['rating*' + i] = 0\n",
    "    return comb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ed040",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = get_dummies(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817fc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = training_features.drop('grade_num', axis = 1)\n",
    "y2 = training_features['grade_num']\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(X2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "testing_features = get_dummies(test_sample)\n",
    "X2 = testing_features.drop('grade_num', axis = 1)\n",
    "y2 = training_features['grade_num']\n",
    "\n",
    "for i, row in X2.iterrows():\n",
    "    predictions.append(round(reg2.predict([X2.loc[i]])[0],2))\n",
    "        \n",
    "testing_features['predicted_grade'] = predictions\n",
    "testing_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-bradford",
   "metadata": {},
   "source": [
    "We decide to make a plot of ratings vs grades for both the actual grades and the predicted grade to see they follow the same trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-idaho",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "plt.scatter(testing_fetures['rating'], testing_fetures['grade_num'], color=\"red\", label = 'Actual Grade')\n",
    "plt.scatter(testing_fetures['rating'], testing_fetures['predicted_grade'], color=\"blue\", label = 'Predicted Grade')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Grade')\n",
    "\n",
    "plt.title('Rating vs Grades for Predicted Grades and Actual Grades')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "x = testing_fetures['rating']\n",
    "y = testing_fetures['predicted_grade']\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-kingdom",
   "metadata": {},
   "source": [
    "From the graph, we are able to see while the actual grades varies a lot more than our predicted grades, they do all follow the same trend of correlating positively with rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-memorial",
   "metadata": {},
   "source": [
    "With the trained model, we can predict the grades of reviews with missing expected grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bdf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "missing_features = get_dummies(reviews_df)\n",
    "X2 = missing_features.drop('grade_num', axis = 1)\n",
    "y2 = missing_features['grade_num']\n",
    "\n",
    "for i, row in X2.iterrows():\n",
    "    predictions.append(round(reg2.predict([X2.loc[i]])[0],2))\n",
    "        \n",
    "reviews_df['predicted_grade'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35f711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_df[pd.isnull(reviews_df[\"grade_num\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-briefing",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-georgia",
   "metadata": {},
   "source": [
    "With this turorial, we analyzed the salary and review data for each of the professors in UMD. From the data analysis and visualizations we created, we discovered that the salary correlates negatively with a professor's rating and positively with the amount of different courses a professor has taught. We are also able to see that the department a professor is in plays a role in the expected salary of a professor and the expected amount of different classes a professor has to teach. With these new insights, we created two models that can predict the salary of a professor based on the professor's rating, department, and number of courses the professor teaches, as well as predict the grade of a student in a class based on the rating the student left, the salary of the professor and the department of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-treaty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
